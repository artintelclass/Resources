{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named torch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0c1724bf6d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named torch"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTrain Step: 60000\tLoss: 0.147\tAccuracy: 86.41%\n",
      "Epoch: 1 \tTrain Step: 60000\tLoss: 0.107\tAccuracy: 89.89%\n",
      "Epoch: 2 \tTrain Step: 60000\tLoss: 0.088\tAccuracy: 91.57%\n",
      "Epoch: 3 \tTrain Step: 60000\tLoss: 0.075\tAccuracy: 92.64%\n",
      "Epoch: 4 \tTrain Step: 60000\tLoss: 0.067\tAccuracy: 93.41%\n"
     ]
    }
   ],
   "source": [
    "# D_in is input dimension; H is hidden dimension; D_out is output dimension.\n",
    "D_in, H, D_out, epochs, learning_rate = 784, 200, 10, 5, .1\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. Each Linear Module computes output from input using a\n",
    "# linear function, and holds internal Variables for its weight and bias.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H, bias=False),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(H, D_out, bias=False),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Set stochastic gradient descent\n",
    "model.optimiser = torch.optim.SGD(model.parameters(), learning_rate)\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "# for evaluation\n",
    "train_loss = []\n",
    "train_accu = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    i = 0\n",
    "    for data, target in train_loader:\n",
    "        # create one hot encoding with offsets\n",
    "        label = torch.zeros(1,10) +.01\n",
    "        label[0][target]= .99\n",
    "        \n",
    "        # create Variables for backprop\n",
    "        # transform the data into the proper dimensions with .view, 1 row + 784 & 10 columns\n",
    "        data = Variable(data).view(1, D_in)\n",
    "        target = Variable(label.view(1, D_out), requires_grad=False)\n",
    "        \n",
    "        # Forward pass: \n",
    "        pred = model(data)\n",
    "\n",
    "        # Compute loss:\n",
    "        loss = loss_fn(pred, target)\n",
    "\n",
    "        # Zero the gradients before running the backward pass:\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Backward pass:\n",
    "        loss.backward()\n",
    "\n",
    "#         # Update the weights using gradient descent. Each parameter is a Variable, so\n",
    "#         # we can access its data and gradients like we did before.\n",
    "#         for param in model.parameters():\n",
    "#             param.data -= learning_rate * param.grad.data\n",
    "        \n",
    "        # Or use the built in optimizer to update the weights\n",
    "        model.optimiser.step()   # update gradients\n",
    "    \n",
    "        # Evaluation: \n",
    "        accuracy = pred.data.max(1)[0] # get the maximum percentage in the array of 10 probabilities\n",
    "        train_accu.append(accuracy)\n",
    "        train_loss.append(loss.data[0])\n",
    "        if i % 100 == 0:\n",
    "            currentAccuracy = (sum(train_accu)/len(train_accu))*100\n",
    "            currentLoss = (sum(train_loss)/len(train_accu))\n",
    "            # overwrite the print line during epoch\n",
    "            print('Epoch: {} \\tTrain Step: {}\\tLoss: {:.3f}\\tAccuracy: {:.2f}%'.format(e, i, currentLoss, currentAccuracy.numpy()[0]), end='\\r')\n",
    "        i += 1\n",
    "        \n",
    "    # print a new line at the end of each epoch\n",
    "    print('Epoch: {} \\tTrain Step: {}\\tLoss: {:.3f}\\tAccuracy: {:.2f}%'.format(e, i, currentLoss, currentAccuracy.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance =  97.52\n"
     ]
    }
   ],
   "source": [
    "# score network\n",
    "scorecard = []\n",
    "\n",
    "for data, target in test_loader:\n",
    "    test = Variable(data, requires_grad=False).view(1, D_in) \n",
    "    output = model(test) # run the forward pass\n",
    "    pred = output.data.max(1)[1].numpy()[0] # get the array index of the maximum percentage\n",
    "    if (pred == target.numpy()[0]):\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        scorecard.append(0)\n",
    "\n",
    "print (\"Performance = \", sum(scorecard) / len(scorecard)*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n",
      "Prediction: 5\n",
      "Score: 99.87%\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "# test it\n",
    "randomDigit = random.randint(0,len(test_loader.dataset))\n",
    "data = test_loader.dataset[randomDigit][0]\n",
    "test = Variable(data, requires_grad=False).view(1, D_in)\n",
    "output = model(test)\n",
    "pred = output.data.max(1)[1].numpy()[0]\n",
    "score = output.data.max(1)[0].numpy()[0]\n",
    "print(\"Label:\", test_loader.dataset[randomDigit][1])\n",
    "print(\"Prediction:\", pred)\n",
    "print(\"Score: {:.2f}%\".format(score*100))\n",
    "if (pred == test_loader.dataset[randomDigit][1]):\n",
    "    print(\"Correct!\")\n",
    "else:\n",
    "    print(\"Wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
