{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to read files\n",
    "\n",
    "# we don't have a header, and we don't want the first column to be index values\n",
    "training = pd.read_csv(\"../mnist_dataset/mnist_train.csv\", header=None, index_col=False)\n",
    "# take the first column and store as labels as numpy array\n",
    "training_labels = np.asfarray(training.iloc[:,0])\n",
    "# delete the first column and use the rest as data as numpy array\n",
    "training_features = np.asfarray(training.drop(columns=[0]))\n",
    "\n",
    "# use pandas to read file\n",
    "# we don't have a header, and we don't want the first column to be index values\n",
    "test = pd.read_csv(\"../mnist_dataset/mnist_test.csv\", header=None, index_col=False)\n",
    "# take the first column and store as labels as numpy array\n",
    "test_labels = np.asfarray(test.iloc[:,0])\n",
    "# delete the first column and use the rest as data as numpy array\n",
    "test_features = np.asfarray(test.drop(columns=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[784])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpfJASB7\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x10a13fa10>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpfJASB7', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 1 hidden layers and 500 nodes in the hidden layer.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    # Three hidden layers\n",
    "    hidden_units=[512, 512],\n",
    "    optimizer=tf.train.RMSPropOptimizer(1e-4),\n",
    "    # The model must choose between 10 classes.\n",
    "    n_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training inputs\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": training_features},\n",
    "    y=training_labels.astype(np.int32),\n",
    "    num_epochs=5,\n",
    "    batch_size=100,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpfJASB7/model.ckpt.\n",
      "INFO:tensorflow:loss = 15840.816, step = 1\n",
      "INFO:tensorflow:global_step/sec: 178.762\n",
      "INFO:tensorflow:loss = 578.55664, step = 101 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.726\n",
      "INFO:tensorflow:loss = 244.06471, step = 201 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.075\n",
      "INFO:tensorflow:loss = 365.6209, step = 301 (0.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.5\n",
      "INFO:tensorflow:loss = 167.69562, step = 401 (0.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.274\n",
      "INFO:tensorflow:loss = 92.98358, step = 501 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.35\n",
      "INFO:tensorflow:loss = 138.77396, step = 601 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.595\n",
      "INFO:tensorflow:loss = 84.2404, step = 701 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.26\n",
      "INFO:tensorflow:loss = 29.914188, step = 801 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.215\n",
      "INFO:tensorflow:loss = 133.36053, step = 901 (0.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.305\n",
      "INFO:tensorflow:loss = 60.857468, step = 1001 (0.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.232\n",
      "INFO:tensorflow:loss = 64.96863, step = 1101 (0.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.26\n",
      "INFO:tensorflow:loss = 13.641152, step = 1201 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.089\n",
      "INFO:tensorflow:loss = 52.97583, step = 1301 (0.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.805\n",
      "INFO:tensorflow:loss = 82.25042, step = 1401 (0.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.024\n",
      "INFO:tensorflow:loss = 61.64911, step = 1501 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.234\n",
      "INFO:tensorflow:loss = 4.9466195, step = 1601 (0.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.541\n",
      "INFO:tensorflow:loss = 27.454918, step = 1701 (0.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.673\n",
      "INFO:tensorflow:loss = 11.212679, step = 1801 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.009\n",
      "INFO:tensorflow:loss = 16.82043, step = 1901 (0.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.074\n",
      "INFO:tensorflow:loss = 64.87691, step = 2001 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.241\n",
      "INFO:tensorflow:loss = 21.530132, step = 2101 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.404\n",
      "INFO:tensorflow:loss = 31.049957, step = 2201 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.8\n",
      "INFO:tensorflow:loss = 21.782238, step = 2301 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.828\n",
      "INFO:tensorflow:loss = 19.002779, step = 2401 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.697\n",
      "INFO:tensorflow:loss = 9.398676, step = 2501 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.749\n",
      "INFO:tensorflow:loss = 6.6817446, step = 2601 (0.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.551\n",
      "INFO:tensorflow:loss = 0.10436674, step = 2701 (0.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.12\n",
      "INFO:tensorflow:loss = 5.3024893, step = 2801 (0.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.207\n",
      "INFO:tensorflow:loss = 12.08394, step = 2901 (0.636 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpfJASB7/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 14.66584.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x181a8fc950>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": test_features},\n",
    "    y=test_labels.astype(np.int32),\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-03-24-14:34:15\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpfJASB7/model.ckpt-3000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-24-14:34:15\n",
      "INFO:tensorflow:Saving dict for global step 3000: accuracy = 0.9617, average_loss = 0.65246356, global_step = 3000, loss = 82.590324\n",
      "\n",
      "Test Accuracy: 96.17%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "print(\"\\nTest Accuracy: {0:.2f}%\\n\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpfJASB7/model.ckpt-3000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181b602690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 1\n",
      "Labeled: 1\n"
     ]
    }
   ],
   "source": [
    "# Predict single image\n",
    "\n",
    "whichImage = random.randint(0,len(test_features))\n",
    "# Get image from test set\n",
    "test_image = test_features[whichImage].reshape(1, 784)\n",
    "\n",
    "# Prepare the input data\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': test_image}, shuffle=False)\n",
    "\n",
    "# Use the model to predict the images class\n",
    "preds = list(classifier.predict(input_fn))\n",
    "\n",
    "# Display\n",
    "plt.imshow(np.reshape(test_image, [28, 28]), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "p = int(preds[0]['classes'][0])\n",
    "print(\"Model prediction:\", p)\n",
    "print(\"Labeled:\",test_labels[whichImage].astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
