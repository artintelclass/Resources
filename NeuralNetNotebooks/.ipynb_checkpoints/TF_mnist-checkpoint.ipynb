{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to read files\n",
    "\n",
    "# we don't have a header, and we don't want the first column to be index values\n",
    "training = pd.read_csv(\"../mnist_dataset/mnist_train.csv\", header=None, index_col=False)\n",
    "# take the first column and store as labels as numpy array\n",
    "training_labels = np.asfarray(training.iloc[:,0])\n",
    "# delete the first column and use the rest as data as numpy array\n",
    "training_features = np.asfarray(training.drop(columns=[0]))\n",
    "\n",
    "# use pandas to read file\n",
    "# we don't have a header, and we don't want the first column to be index values\n",
    "test = pd.read_csv(\"../mnist_dataset/mnist_test.csv\", header=None, index_col=False)\n",
    "# take the first column and store as labels as numpy array\n",
    "test_labels = np.asfarray(test.iloc[:,0])\n",
    "# delete the first column and use the rest as data as numpy array\n",
    "test_features = np.asfarray(test.drop(columns=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[784])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpvkzGGT\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1820907a10>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpvkzGGT', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 1 hidden layers and 500 nodes in the hidden layer.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    # Three hidden layers\n",
    "    hidden_units=[512, 512],\n",
    "    optimizer=tf.train.RMSPropOptimizer(1e-4),\n",
    "    # The model must choose between 10 classes.\n",
    "    n_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training inputs\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": training_features},\n",
    "    y=training_labels.astype(np.int32),\n",
    "    num_epochs=5,\n",
    "    batch_size=100,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpvkzGGT/model.ckpt.\n",
      "INFO:tensorflow:loss = 8923.076, step = 1\n",
      "INFO:tensorflow:global_step/sec: 178.611\n",
      "INFO:tensorflow:loss = 283.03595, step = 101 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.075\n",
      "INFO:tensorflow:loss = 196.35085, step = 201 (0.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.468\n",
      "INFO:tensorflow:loss = 93.924286, step = 301 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.865\n",
      "INFO:tensorflow:loss = 110.778595, step = 401 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.622\n",
      "INFO:tensorflow:loss = 94.35284, step = 501 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.464\n",
      "INFO:tensorflow:loss = 110.418655, step = 601 (0.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.775\n",
      "INFO:tensorflow:loss = 29.855911, step = 701 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.335\n",
      "INFO:tensorflow:loss = 122.81553, step = 801 (0.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.417\n",
      "INFO:tensorflow:loss = 40.06274, step = 901 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.861\n",
      "INFO:tensorflow:loss = 133.9892, step = 1001 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.527\n",
      "INFO:tensorflow:loss = 47.792088, step = 1101 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.828\n",
      "INFO:tensorflow:loss = 49.26864, step = 1201 (0.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.851\n",
      "INFO:tensorflow:loss = 28.930939, step = 1301 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.593\n",
      "INFO:tensorflow:loss = 1.9079232, step = 1401 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.603\n",
      "INFO:tensorflow:loss = 25.59445, step = 1501 (0.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.802\n",
      "INFO:tensorflow:loss = 35.257957, step = 1601 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.734\n",
      "INFO:tensorflow:loss = 19.823833, step = 1701 (0.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.174\n",
      "INFO:tensorflow:loss = 24.638151, step = 1801 (0.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.862\n",
      "INFO:tensorflow:loss = 52.218063, step = 1901 (0.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.119\n",
      "INFO:tensorflow:loss = 40.224483, step = 2001 (0.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.641\n",
      "INFO:tensorflow:loss = 3.0476415, step = 2101 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.018\n",
      "INFO:tensorflow:loss = 13.238264, step = 2201 (0.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.077\n",
      "INFO:tensorflow:loss = 4.2514124, step = 2301 (0.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.541\n",
      "INFO:tensorflow:loss = 31.714184, step = 2401 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.235\n",
      "INFO:tensorflow:loss = 7.7971325, step = 2501 (0.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.871\n",
      "INFO:tensorflow:loss = 41.743916, step = 2601 (0.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.118\n",
      "INFO:tensorflow:loss = 6.963586, step = 2701 (0.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.511\n",
      "INFO:tensorflow:loss = 0.10971358, step = 2801 (0.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.874\n",
      "INFO:tensorflow:loss = 2.2559488, step = 2901 (0.650 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpvkzGGT/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 21.671202.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x18208ae6d0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": test_features},\n",
    "    y=test_labels.astype(np.int32),\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-03-24-12:39:26\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpvkzGGT/model.ckpt-3000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-24-12:39:27\n",
      "INFO:tensorflow:Saving dict for global step 3000: accuracy = 0.9502, average_loss = 0.8739936, global_step = 3000, loss = 110.632095\n",
      "\n",
      "Test Accuracy: 95.02%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "print(\"\\nTest Accuracy: {0:.2f}%\\n\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpvkzGGT/model.ckpt-3000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1820875d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 1\n",
      "Labeled: 1\n"
     ]
    }
   ],
   "source": [
    "# Predict single image\n",
    "\n",
    "whichImage = random.randint(0,len(test_features))\n",
    "# Get image from test set\n",
    "test_image = test_features[whichImage].reshape(1, 784)\n",
    "\n",
    "# Prepare the input data\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': test_image}, shuffle=False)\n",
    "\n",
    "# Use the model to predict the images class\n",
    "preds = list(classifier.predict(input_fn))\n",
    "\n",
    "# Display\n",
    "plt.imshow(np.reshape(test_image, [28, 28]), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "p = int(preds[0]['classes'][0])\n",
    "print(\"Model prediction:\", p)\n",
    "print(\"Labeled:\",test_labels[whichImage].astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
