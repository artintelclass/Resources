{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to read files\n",
    "\n",
    "# we don't have a header, and we don't want the first column to be index values\n",
    "training = pd.read_csv(\"../mnist_dataset/mnist_train.csv\", header=None, index_col=False)\n",
    "# take the first column and store as labels as numpy array\n",
    "training_labels = np.asfarray(training.iloc[:,0])\n",
    "# delete the first column and use the rest as data as numpy array\n",
    "training_features = np.asfarray(training.drop(columns=[0]))\n",
    "\n",
    "# use pandas to read file\n",
    "# we don't have a header, and we don't want the first column to be index values\n",
    "test = pd.read_csv(\"../mnist_dataset/mnist_test.csv\", header=None, index_col=False)\n",
    "# take the first column and store as labels as numpy array\n",
    "test_labels = np.asfarray(test.iloc[:,0])\n",
    "# delete the first column and use the rest as data as numpy array\n",
    "test_features = np.asfarray(test.drop(columns=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[784])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpy9reA6\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x181d00d1d0>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpy9reA6', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 1 hidden layers and 500 nodes in the hidden layer.\n",
    "# classifier = tf.estimator.DNNClassifier(\n",
    "#     feature_columns=feature_columns,\n",
    "#     # Three hidden layers\n",
    "#     hidden_units=[512, 512],\n",
    "#     optimizer=tf.train.RMSPropOptimizer(1e-4),\n",
    "#     # The model must choose between 10 classes.\n",
    "#     n_classes=10)\n",
    "def my_model(features, labels, mode, params):\n",
    "    \"\"\"DNN with three hidden layers, and dropout of 0.1 probability.\"\"\"\n",
    "    # Create three fully connected layers each layer having a dropout\n",
    "    # probability of 0.1.\n",
    "   \n",
    "    net = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    for units in params['hidden_units']:\n",
    "        net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n",
    "\n",
    "    # Compute logits (1 per class).\n",
    "    logits = tf.layers.dense(net, params['n_classes'], activation=None)\n",
    "\n",
    "    # Compute predictions.\n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class_ids': predicted_classes[:, tf.newaxis],\n",
    "            'probabilities': tf.nn.softmax(logits),\n",
    "            'logits': logits,\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # Compute loss.\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Compute evaluation metrics.\n",
    "    accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                                   predictions=predicted_classes,\n",
    "                                   name='acc_op')\n",
    "    metrics = {'accuracy': accuracy}\n",
    "    tf.summary.scalar('accuracy', accuracy[1])\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "    # Create training op.\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training inputs\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": training_features},\n",
    "    y=training_labels.astype(np.int32),\n",
    "    num_epochs=5,\n",
    "    batch_size=100,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpy9reA6/model.ckpt.\n",
      "INFO:tensorflow:loss = 8879.324, step = 1\n",
      "INFO:tensorflow:global_step/sec: 176.827\n",
      "INFO:tensorflow:loss = 263.7546, step = 101 (0.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.627\n",
      "INFO:tensorflow:loss = 239.70265, step = 201 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.905\n",
      "INFO:tensorflow:loss = 127.495735, step = 301 (0.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.834\n",
      "INFO:tensorflow:loss = 154.41296, step = 401 (0.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.935\n",
      "INFO:tensorflow:loss = 188.70268, step = 501 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.427\n",
      "INFO:tensorflow:loss = 151.07573, step = 601 (0.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.318\n",
      "INFO:tensorflow:loss = 159.1963, step = 701 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.038\n",
      "INFO:tensorflow:loss = 64.39851, step = 801 (0.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.746\n",
      "INFO:tensorflow:loss = 91.664055, step = 901 (0.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.797\n",
      "INFO:tensorflow:loss = 21.59003, step = 1001 (0.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.153\n",
      "INFO:tensorflow:loss = 26.264408, step = 1101 (0.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.546\n",
      "INFO:tensorflow:loss = 73.81293, step = 1201 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.685\n",
      "INFO:tensorflow:loss = 0.36074725, step = 1301 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.529\n",
      "INFO:tensorflow:loss = 50.201717, step = 1401 (0.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.624\n",
      "INFO:tensorflow:loss = 50.5518, step = 1501 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.57\n",
      "INFO:tensorflow:loss = 59.976826, step = 1601 (0.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.55\n",
      "INFO:tensorflow:loss = 66.16539, step = 1701 (0.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.809\n",
      "INFO:tensorflow:loss = 51.209007, step = 1801 (0.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.809\n",
      "INFO:tensorflow:loss = 17.929028, step = 1901 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.333\n",
      "INFO:tensorflow:loss = 0.3791613, step = 2001 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.115\n",
      "INFO:tensorflow:loss = 8.375483, step = 2101 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.93\n",
      "INFO:tensorflow:loss = 67.408295, step = 2201 (0.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.131\n",
      "INFO:tensorflow:loss = 60.023384, step = 2301 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.968\n",
      "INFO:tensorflow:loss = 36.95838, step = 2401 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.245\n",
      "INFO:tensorflow:loss = 0.5557978, step = 2501 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.866\n",
      "INFO:tensorflow:loss = 16.427511, step = 2601 (0.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.894\n",
      "INFO:tensorflow:loss = 28.506155, step = 2701 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.465\n",
      "INFO:tensorflow:loss = 0.012306302, step = 2801 (0.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.052\n",
      "INFO:tensorflow:loss = 0.014312718, step = 2901 (0.699 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpy9reA6/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 11.710333.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x181bd95610>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": test_features},\n",
    "    y=test_labels.astype(np.int32),\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-03-24-10:29:37\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpy9reA6/model.ckpt-3000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-24-10:29:38\n",
      "INFO:tensorflow:Saving dict for global step 3000: accuracy = 0.9549, average_loss = 0.7230065, global_step = 3000, loss = 91.519806\n",
      "\n",
      "Test Accuracy: 95.49%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "print(\"\\nTest Accuracy: {0:.2f}%\\n\".format(accuracy_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/2z/khrnj_dn3zv_t52wp04myk200000gn/T/tmpdV5z9m/model.ckpt-12001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a216f0b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 8\n",
      "Labeled: 8\n"
     ]
    }
   ],
   "source": [
    "# Predict single image\n",
    "\n",
    "whichImage = random.randint(0,len(test_features))\n",
    "# Get image from test set\n",
    "test_image = test_features[whichImage].reshape(1, 784)\n",
    "\n",
    "# Prepare the input data\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': test_image}, shuffle=False)\n",
    "\n",
    "# Use the model to predict the images class\n",
    "preds = list(classifier.predict(input_fn))\n",
    "\n",
    "# Display\n",
    "plt.imshow(np.reshape(test_image, [28, 28]), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "p = int(preds[0]['classes'][0])\n",
    "print(\"Model prediction:\", p)\n",
    "print(\"Labeled:\",test_labels[whichImage].astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5.0\n",
       "0    1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
