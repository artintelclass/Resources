{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "lr = 0.1 # learning rate\n",
    "epochs = 6\n",
    "batch_size = 100\n",
    "# calculate the number of steps based on the number of samples, batch size, and number of epochs\n",
    "num_steps = len(mnist.train.images)/batch_size * epochs \n",
    "\n",
    "# Network Parameters\n",
    "num_input = 784\n",
    "num_classes = 10 \n",
    "\n",
    "# Feature columns describe how to use the input.\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[784])] # there is no label, so we simply use x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset. Features needs to be a dictionary, labels can be any list or array.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict({'x':features}), labels.astype(np.int32)))\n",
    "    # Shuffle, repeat, and batch the examples. Dataset allows manipulation. \n",
    "    # Choose number larger than dataset to insure complete shuffle (size of buffer)\n",
    "    dataset = dataset.shuffle(70000).repeat().batch(batch_size)\n",
    "    # Return the dataset.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(features, labels, mode, params):\n",
    "    #Input layer\n",
    "    net = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    \n",
    "    #Hidden layers\n",
    "    for units in params['hidden_units']:\n",
    "        net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n",
    "    \n",
    "    # Output layer. Compute logits (1 per class).\n",
    "    logits = tf.layers.dense(net, params['n_classes'], activation=None)\n",
    "\n",
    "    # Compute predictions.\n",
    "    predicted_classes = tf.argmax(logits, 1) \n",
    "    \n",
    "    # If we're just querying, return \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class_ids': predicted_classes[:, tf.newaxis],\n",
    "            'probabilities': tf.nn.softmax(logits),\n",
    "            'logits': logits,\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # Compute loss. Sparse is for non-one hot encoded labels\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Compute evaluation metrics.\n",
    "    accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                                   predictions=predicted_classes,\n",
    "                                   name='acc_op')\n",
    "    metrics = {'accuracy': accuracy}\n",
    "\n",
    "    # If we're evaulating return evaluation\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "    # Create training op.\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN # make sure mode is train\n",
    "\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=lr)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c1b10ba10>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': './tf_export_model/', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(\n",
    "    model_fn=neural_net,\n",
    "    model_dir='./tf_export_model/',\n",
    "    params={\n",
    "        'feature_columns': feature_columns,\n",
    "        'hidden_units': [512, 512],\n",
    "        'n_classes': 10\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./tf_export_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.32216, step = 1\n",
      "INFO:tensorflow:global_step/sec: 193.101\n",
      "INFO:tensorflow:loss = 0.311236, step = 101 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.657\n",
      "INFO:tensorflow:loss = 0.608, step = 201 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.958\n",
      "INFO:tensorflow:loss = 0.158929, step = 301 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.949\n",
      "INFO:tensorflow:loss = 0.126046, step = 401 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.459\n",
      "INFO:tensorflow:loss = 0.0792294, step = 501 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.213\n",
      "INFO:tensorflow:loss = 0.0851761, step = 601 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.642\n",
      "INFO:tensorflow:loss = 0.0911393, step = 701 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.489\n",
      "INFO:tensorflow:loss = 0.0418112, step = 801 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.477\n",
      "INFO:tensorflow:loss = 0.050328, step = 901 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.339\n",
      "INFO:tensorflow:loss = 0.0524017, step = 1001 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.527\n",
      "INFO:tensorflow:loss = 0.0891215, step = 1101 (0.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.589\n",
      "INFO:tensorflow:loss = 0.0381866, step = 1201 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.152\n",
      "INFO:tensorflow:loss = 0.0516822, step = 1301 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.999\n",
      "INFO:tensorflow:loss = 0.0814231, step = 1401 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.347\n",
      "INFO:tensorflow:loss = 0.147052, step = 1501 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.072\n",
      "INFO:tensorflow:loss = 0.0195459, step = 1601 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.863\n",
      "INFO:tensorflow:loss = 0.0128628, step = 1701 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.427\n",
      "INFO:tensorflow:loss = 0.0123272, step = 1801 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.003\n",
      "INFO:tensorflow:loss = 0.0298089, step = 1901 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.265\n",
      "INFO:tensorflow:loss = 0.0712572, step = 2001 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.851\n",
      "INFO:tensorflow:loss = 0.0351057, step = 2101 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.213\n",
      "INFO:tensorflow:loss = 0.036783, step = 2201 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.104\n",
      "INFO:tensorflow:loss = 0.0305505, step = 2301 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.01\n",
      "INFO:tensorflow:loss = 0.0138712, step = 2401 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.394\n",
      "INFO:tensorflow:loss = 0.0305369, step = 2501 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.292\n",
      "INFO:tensorflow:loss = 0.0143974, step = 2601 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.842\n",
      "INFO:tensorflow:loss = 0.0251592, step = 2701 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.227\n",
      "INFO:tensorflow:loss = 0.00648472, step = 2801 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.621\n",
      "INFO:tensorflow:loss = 0.0214536, step = 2901 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.722\n",
      "INFO:tensorflow:loss = 0.00901699, step = 3001 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.244\n",
      "INFO:tensorflow:loss = 0.0336289, step = 3101 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.903\n",
      "INFO:tensorflow:loss = 0.0249896, step = 3201 (0.457 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3300 into ./tf_export_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.062838.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1c1a82b910>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model.\n",
    "# Pass the training input function into model.train as a lambda\n",
    "model.train(lambda:training_input_fn(mnist.train.images,mnist.train.labels,batch_size),steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
    " \n",
    "    features=dict({'x':features})\n",
    "    if labels is None:\n",
    "        # No labels, use only features. For querying.\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, labels.astype(np.int32))\n",
    "\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "    # Batch the examples\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-19-14:24:21\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tf_export_model/model.ckpt-3300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-19-14:24:22\n",
      "INFO:tensorflow:Saving dict for global step 3300: accuracy = 0.9806, global_step = 3300, loss = 0.0634114\n",
      "\n",
      "Test set accuracy: 98.06%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = model.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(mnist.test.images,mnist.test.labels,batch_size))\n",
    "\n",
    "# eval_result is a dict\n",
    "acc=eval_result[\"accuracy\"]\n",
    "print('\\nTest set accuracy: {0:0.2f}%\\n'.format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tf_export_model/model.ckpt-3300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c1b9df190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 4\n",
      "Actual Label: 4\n"
     ]
    }
   ],
   "source": [
    "# Predict single image\n",
    "\n",
    "whichImage = random.randint(0,len(mnist.test.images))\n",
    "# Get image from test set\n",
    "test_image = mnist.test.images[whichImage].reshape(1, 784)\n",
    "\n",
    "preds = list(model.predict(input_fn=lambda:eval_input_fn(test_image,None,1)))\n",
    "\n",
    "# Display\n",
    "plt.imshow(np.reshape(test_image, [28, 28]), cmap='gray')\n",
    "plt.show()\n",
    "print(\"Model prediction:\", preds[0]['class_ids'][0])\n",
    "print(\"Actual Label:\",mnist.test.labels[whichImage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
